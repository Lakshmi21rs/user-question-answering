# user-question-answering
This project builds a Question Answering (QA) system using BERT (Bidirectional Encoder Representations from Transformers). Given a textual context (passage) and a question, the system predicts the most probable answer from the context.

# Project Description
This project aims to develop a machine learning model capable of automatically answering questions based on given passages or documents. It involves:

1.Collecting a dataset of question-answer pairs along with relevant contexts
2.Preprocessing the text data to extract features and encode contextual information
3.Fine-tuning a pre-trained BERT model
4.Evaluating model performance using accuracy and F1-score
5.Deploying a Streamlit web app for real-time question answering

# Technologies Used
1.Python 3.9
2.Hugging Face Transformers
3.PyTorch
4.Datasets (Hugging Face)
5.Streamlit
